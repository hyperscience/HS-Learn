{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "plt.rcParams['image.cmap'] = 'gray' # we want our images to be show black and white, not heat-mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional MNIST model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a couple hidden layers not just one and we don't like code duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(inp, output_channels, scope_name):\n",
    "    # We want to get the number of channels in `inp`\n",
    "    # `get_shape` return a tf.TensorShape, describing the static shape of `inp`\n",
    "    # and the last element of it is the number of channels\n",
    "    input_channels = inp.get_shape().as_list()[-1]\n",
    "    # The kernel shape is [kernel_height, kernel_width, input_channels, output_channels]\n",
    "    kernel_shape = [3 ,3, input_channels, output_channels]\n",
    "    with tf.variable_scope(scope_name):\n",
    "        kernel = tf.get_variable('kernel', kernel_shape, initializer=tf.random_normal_initializer(stddev=1e-3))\n",
    "        bias = tf.get_variable('bias', [output_channels], initializer=tf.zeros_initializer())\n",
    "    # Strides tells TF the location of the next kernel center relative to the current.\n",
    "    # Padding tells TF how to behave near the edges of the image \n",
    "    # More info about the strides and padding can be found in http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html\n",
    "    processed = tf.nn.conv2d(inp, kernel, strides=[1, 2, 2, 1], padding='VALID') + bias\n",
    "    return tf.nn.leaky_relu(processed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static shape vs Dynamic shape\n",
    "Each tensor has a shape. When we define variables we have to fully define that shape, but when we define placeholders we can omit some of dimentions of the shape (like the batch size dimention). The definition shape is the *static* shape of the tensor. We get the static shape of a tensor with the `get_shape` method. Operations get their shape based on their operands.\n",
    "\n",
    "When we pass the placeholders and we actually compute the tensors, they have a fully-defined shape without `None` dimentions. We call that shape the *dynamic* shape. We can get the dynamic shape using the `tf.shape` function. That shape is useful in some circumstances, but in our case we need the static shape, because we want to compute the static shape of the kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable sharing\n",
    "\n",
    "Using `variable_scope` and `get_variable` is referred in TF as variable sharing. We use them to define our reusable layers, because we don't have to explicitly return and store the variables used in the layers, and they get meaningful names in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.placeholder(tf.float32, [None, 28, 28, 1], name='image')\n",
    "gt_label = tf.placeholder(tf.float32, [None, 10], name='gt_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want `image` to be a batch of 28x28 images with one (luminance) channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1 = convolutional_layer(image, 4, 'conv_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates two variables `conv_1/kernel` for our kernel and `conv_1/bias` for the bias. If we need them we can get them in a simialar way (with `variable_scope` and `get_variable` but we must pass `reuse=True/tf.AUTO_REUSE` to `variable_scope`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_2 = convolutional_layer(hidden_layer_1, 8, 'conv_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That reuse machanism is a good way to prevent copy/paste errors if we forget to rename our layer scopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_2 = convolutional_layer(hidden_layer_1, 8, 'conv_2')\n",
    "print(hidden_layer_2.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_3 = convolutional_layer(hidden_layer_2, 16, 'conv_3')\n",
    "print(hidden_layer_3.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pooled_layer_3 = tf.nn.max_pool(hidden_layer_3, \n",
    "                                    ksize=[1, 2, 2, 1], # how big are our pooling windows (kernels)\n",
    "                                    strides=[1, 2, 2, 1], # has the same meaning as tf.nn.conv2d\n",
    "                                    padding='VALID', # has the same meaning as tf.nn.conv2d\n",
    "                                   )\n",
    "print(max_pooled_layer_3.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_hidden_layer_3 = tf.reshape(max_pooled_layer_3, [-1, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(flattened_hidden_layer_3, 10, name='final_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dense layer is the same as the linear model used in the previous notebook. The only difference (used here, since `tf.layers.dense` has a lot of options) is that it's defined as a layer with `variable_scope` and `get_variable`. Implementing a linear layer using variable sharing is left as an exercise to the reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_probs = tf.nn.softmax(logits)\n",
    "predicted_label = tf.argmax(predicted_label_probs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    labels=gt_label, \n",
    "    logits=logits,\n",
    ")\n",
    "loss = tf.reduce_mean(loss) # since we want the average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, dtype=tf.int32, name='global_step')\n",
    "optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AdamOptimizer` implements a variant of stochastic gradient descent, that behaves better in various contexts: sparse variables, saddle points, etc. and is known for fast convergence, but sadly even though it's advertised to not need learning rate tuning it's still sensitive to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label_index = tf.argmax(gt_label, axis=-1)\n",
    "gt_match = tf.equal(predicted_label, gt_label_index)\n",
    "accuracy = tf.reduce_mean(tf.cast(gt_match, tf.float32), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter('summaries_logdir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer.add_graph(session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(predicted_label_probs, {image: mnist.train.images[0:1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model expects a 28x28 1 channel images we have to reshape our input. If our images where of different sizes we would have to resize them or make our model handle images with different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(predicted_label_probs, {image: mnist.train.images[0:1].reshape([-1, 28, 28, 1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_summary_writer = tf.summary.FileWriter('summaries_logdir/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for one epoch\n",
    "batch_size = 10\n",
    "summaries_op = tf.summary.merge_all()\n",
    "for batch_start in range(0, mnist.train.images.shape[0], batch_size):\n",
    "    # Get the corresponding batches for images and labels\n",
    "    image_batch = mnist.train.images[batch_start:batch_start + batch_size].reshape([-1, 28, 28, 1])\n",
    "    label_batch = mnist.train.labels[batch_start:batch_start + batch_size]\n",
    "    \n",
    "    # Execute one step of the model. Note that train_op doesn't have a value, but it **HAS** to be executed\n",
    "    # in order to train the model\n",
    "    global_step_value, loss_value, accuracy_value, summaries_value, _ = session.run(\n",
    "        [global_step, loss, accuracy, summaries_op, train_op],\n",
    "        {image: image_batch, gt_label: label_batch}\n",
    "    )\n",
    "    if global_step_value % 100 == 0:\n",
    "        # Print the loss and accuracy of the model on the *Trainng* *batch*\n",
    "        print(\"{:6}: loss: {}, accuracy:{} \".format(global_step_value, loss_value, accuracy_value))\n",
    "        summary_writer.add_summary(summaries_value, global_step_value)\n",
    "    if global_step_value % 1000 == 0:\n",
    "        # Compute the loss and accuracy on the whole *Validation* set. \n",
    "        # Note 0: usually the validation set will be too big to compute validations on the whole set\n",
    "        # Note 1: there is no `train_op` in the tensors we pass to run, so the model doesn't learn \n",
    "        #   anything from the validation set (this would be bad)\n",
    "        global_step_value, loss_value, accuracy_value, summaries_value = session.run(\n",
    "            [global_step, loss, accuracy, summaries_op],\n",
    "            {image: mnist.validation.images.reshape([-1, 28, 28, 1]), \n",
    "             gt_label: mnist.validation.labels}\n",
    "        )\n",
    "        val_summary_writer.add_summary(summaries_value, global_step_value)\n",
    "        print(\"VAL: {:6}: loss: {}, accuracy:{} \".format(global_step_value, loss_value, accuracy_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the examples that are causing problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_probs_val, gt_match_val = session.run(\n",
    "    [predicted_label_probs, gt_match],\n",
    "    {image: mnist.validation.images.reshape([-1, 28, 28, 1]), gt_label: mnist.validation.labels}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~gt_match_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_predicted_label_probs_val = predicted_label_probs_val[~gt_match_val]\n",
    "failed_images_val = mnist.validation.images[~gt_match_val]\n",
    "failed_labels_val = mnist.validation.labels[~gt_match_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_predicted_label_probs_val[0], failed_labels_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(failed_images_val[0].reshape([28, 28]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving our models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save our mode we use `tf.train.Saver`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `save` method we pass a session and a path for saving the model. Usually we want to pass a `global_step` parameter, so we can save every few thousand steps and still know which model is more trained than others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big downside is that our model consists of 3 types of files:\n",
    " - `.data-#####-of-#####` files, that contains the tensor values (currently we have only one such file).\n",
    " - `.index` file, that contains tensor metadata: what tensors do we have in our data files, in which files at which offset, checksums, etc.\n",
    " - `.meta` file, that describes our graph's structure if we don't want to build it in our source. Since we build the graph in the source we don't need it (for our usecase) and we can disable it's generation with `write_meta_graph=False`\n",
    "\n",
    "More info can be found in [this SO thread](https://stackoverflow.com/questions/41265035/tensorflow-why-there-are-3-files-after-saving-the-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(session, 'saved_model/model.ckpt', global_step=global_step_value, write_meta_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(session, '...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
