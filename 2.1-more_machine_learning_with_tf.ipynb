{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "plt.rcParams['image.cmap'] = 'gray' # we want our images to be show black and white, not heat-mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional MNIST model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a couple hidden layers not just one and we don't like code duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(inp, output_channels, scope_name):\n",
    "    # We want to get the number of channels in `inp`\n",
    "    # `get_shape` return a list, describing the static shape of `inp`\n",
    "    # and the last element of it is the number of channels\n",
    "    input_channels = inp.get_shape().as_list()[-1]\n",
    "    # The kernel shape is [kernel_height, kernel_width, input_channels, output_channels]\n",
    "    kernel_shape = [3 ,3, input_channels, output_channels]\n",
    "    with tf.variable_scope(scope_name):\n",
    "        kernel = tf.get_variable('kernel', kernel_shape, initializer=tf.random_normal_initializer(stddev=1e-3))\n",
    "        bias = tf.get_variable('bias', [output_channels], initializer=tf.zeros_initializer())\n",
    "    # Strides tells TF the location of the next kernel center relative to the current.\n",
    "    # Padding tells TF how to behave near the edges of the image \n",
    "    # **TODO** add images describing strides and padding\n",
    "    processed = tf.nn.conv2d(inp, kernel, strides=[1, 2, 2, 1], padding='VALID') + bias\n",
    "    return tf.nn.leaky_relu(processed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.placeholder(tf.float32, [None, 28, 28, 1], name='image')\n",
    "gt_label = tf.placeholder(tf.float32, [None, 10], name='gt_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want `image` to be a batch of 28x28 images with one (luminance) channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1 = convolutional_layer(image, 4, 'conv_1')\n",
    "hidden_layer_2 = convolutional_layer(hidden_layer_1, 8, 'conv_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_2 = convolutional_layer(hidden_layer_1, 8, 'conv_2')\n",
    "print(hidden_layer_2.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_3 = convolutional_layer(hidden_layer_2, 16, 'conv_3')\n",
    "print(hidden_layer_3.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_hidden_layer_3 = tf.reshape(hidden_layer_3, [-1, 2 * 2 * 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(flattened_hidden_layer_3, 10, name='final_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_probs = tf.nn.softmax(logits)\n",
    "predicted_label = tf.argmax(predicted_label_probs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    labels=gt_label, \n",
    "    logits=logits,\n",
    ")\n",
    "loss = tf.reduce_mean(loss) # since we want the average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, dtype=tf.int32, name='global_step')\n",
    "optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label_index = tf.argmax(gt_label, axis=-1)\n",
    "gt_match = tf.equal(predicted_label, gt_label_index)\n",
    "accuracy = tf.reduce_mean(tf.cast(gt_match, tf.float32), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter('summaries_logdir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer.add_graph(session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(predicted_label_probs, {image: mnist.train.images[0:1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(predicted_label_probs, {image: mnist.train.images[0:1].reshape([-1, 28, 28, 1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_summary_writer = tf.summary.FileWriter('summaries_logdir/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for one epoch\n",
    "batch_size = 10\n",
    "summaries_op = tf.summary.merge_all()\n",
    "for batch_start in range(0, mnist.train.images.shape[0], batch_size):\n",
    "    # Get the corresponding batches for images and labels\n",
    "    image_batch = mnist.train.images[batch_start:batch_start + batch_size].reshape([-1, 28, 28, 1])\n",
    "    label_batch = mnist.train.labels[batch_start:batch_start + batch_size]\n",
    "    \n",
    "    # Execute one step of the model. Note that train_op doesn't have a value, but it **HAS** to be executed\n",
    "    # in order to train the model\n",
    "    global_step_value, loss_value, accuracy_value, summaries_value, _ = session.run(\n",
    "        [global_step, loss, accuracy, summaries_op, train_op],\n",
    "        {image: image_batch, gt_label: label_batch}\n",
    "    )\n",
    "    if global_step_value % 100 == 0:\n",
    "        # Print the loss and accuracy of the model on the *Trainng* *batch*\n",
    "        print(\"{:6}: loss: {}, accuracy:{} \".format(global_step_value, loss_value, accuracy_value))\n",
    "        summary_writer.add_summary(summaries_value, global_step_value)\n",
    "    if global_step_value % 1000 == 0:\n",
    "        # Compute the loss and accuracy on the whole *Validation* set. \n",
    "        # Note 0: usually the validation set will be too big to compute validations on the whole set\n",
    "        # Note 1: there is no `train_op` in the tensors we pass to run, so the model doesn't learn \n",
    "        #   anything from the validation set (this would be bad)\n",
    "        global_step_value, loss_value, accuracy_value, summaries_value = session.run(\n",
    "            [global_step, loss, accuracy, summaries_op],\n",
    "            {image: mnist.validation.images.reshape([-1, 28, 28, 1]), \n",
    "             gt_label: mnist.validation.labels}\n",
    "        )\n",
    "        val_summary_writer.add_summary(summaries_value, global_step_value)\n",
    "        print(\"VAL: {:6}: loss: {}, accuracy:{} \".format(global_step_value, loss_value, accuracy_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the examples that are causing problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_probs_val, gt_match_val = session.run(\n",
    "    [predicted_label_probs, gt_match],\n",
    "    {image: mnist.validation.images.reshape([-1, 28, 28, 1]), gt_label: mnist.validation.labels}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~gt_match_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_predicted_label_probs_val = predicted_label_probs_val[~gt_match_val]\n",
    "failed_images_val = mnist.validation.images[~gt_match_val]\n",
    "failed_labels_val = mnist.validation.labels[~gt_match_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_predicted_label_probs_val[0], failed_labels_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(failed_images_val[0].reshape([28, 28]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving our models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(session, 'saved_model/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(session, 'saved_model/model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
