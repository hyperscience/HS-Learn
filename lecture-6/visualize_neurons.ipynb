{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 299\n",
    "\n",
    "TENSORFLOW_MODELS_ROOT = '.'\n",
    "INCEPTION_CHECKPOINT_DIR = '.'\n",
    "CHECKPOINT_FILE = os.path.join(\n",
    "    INCEPTION_CHECKPOINT_DIR, 'inception_resnet_v2_2016_08_30.ckpt')\n",
    "\n",
    "MALAMUTE_PATH = './images/malamute.png'\n",
    "HUSKY_PATH = './images/Siberian-husky.jpg'\n",
    "\n",
    "MALAMUTE_IMAGE = Image.open(MALAMUTE_PATH)\n",
    "HUSKY_IMAGE = Image.open(HUSKY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToJpeg(im):\n",
    "    with BytesIO() as f:\n",
    "        im.save(f, format='JPEG')\n",
    "        return f.getvalue()\n",
    "    \n",
    "\n",
    "def create_readable_names_for_imagenet_labels():\n",
    "    \"\"\"Create a dict mapping label id to human readable string.\n",
    "    Returns:\n",
    "      labels_to_names: dictionary where keys are integers from to 1000\n",
    "      and values are human-readable names.\n",
    "    We retrieve a synset file, which contains a list of valid synset labels used\n",
    "    by ILSVRC competition. There is one synset one per line, eg.\n",
    "          #   n01440764\n",
    "          #   n01443537\n",
    "    We also retrieve a synset_to_human_file, which contains a mapping from synsets\n",
    "    to human-readable names for every synset in Imagenet. These are stored in a\n",
    "    tsv format, as follows:\n",
    "          #   n02119247    black fox\n",
    "          #   n02119359    silver fox\n",
    "    We assign each synset (in alphabetical order) an integer, starting from 1\n",
    "    (since 0 is reserved for the background class).\n",
    "    \"\"\"\n",
    "\n",
    "    # pylint: disable=g-line-too-long\n",
    "    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/slim/datasets'\n",
    "    synset_url = '{}/imagenet_lsvrc_2015_synsets.txt'.format(base_url)\n",
    "    synset_to_human_url = '{}/imagenet_metadata.txt'.format(base_url)\n",
    "\n",
    "    synset_list = [s.strip() for s in requests.get(synset_url).content.decode().split('\\n') if len(s.strip())]\n",
    "    num_synsets_in_ilsvrc = len(synset_list)\n",
    "    print(synset_list[-1])\n",
    "    assert num_synsets_in_ilsvrc == 1000\n",
    "\n",
    "    synset_to_human_list = requests.get(synset_to_human_url).content.decode().split('\\n')[:-1]\n",
    "    num_synsets_in_all_imagenet = len(synset_to_human_list)\n",
    "    assert num_synsets_in_all_imagenet == 21842\n",
    "\n",
    "    synset_to_human = {}\n",
    "    for s in synset_to_human_list:\n",
    "        parts = s.strip().split('\\t')\n",
    "        assert len(parts) == 2\n",
    "        synset = parts[0]\n",
    "        human = parts[1]\n",
    "        synset_to_human[synset] = human\n",
    "\n",
    "    label_index = 1\n",
    "    labels_to_names = {0: 'background'}\n",
    "    for synset in synset_list:\n",
    "        name = synset_to_human[synset]\n",
    "        labels_to_names[label_index] = name\n",
    "        label_index += 1\n",
    "\n",
    "    return labels_to_names\n",
    "\n",
    "labels_mapping = create_readable_names_for_imagenet_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "from skimage.io import imread, imsave, imshow\n",
    "\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase plot sizes\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(\n",
    "    TENSORFLOW_MODELS_ROOT, 'models/research/slim/nets'))\n",
    "from inception_resnet_v2 import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.placeholder(tf.float32, shape=(None,IMAGE_SIZE,IMAGE_SIZE,3), name='input_image')\n",
    "# NOTE: NO RESCALING!!!\n",
    "\n",
    "print(input_tensor)\n",
    "#Load the model\n",
    "arg_scope = inception_resnet_v2_arg_scope()\n",
    "with slim.arg_scope(arg_scope):\n",
    "    logits, end_points = inception_resnet_v2(input_tensor, is_training=False, reuse=None)\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, CHECKPOINT_FILE)\n",
    "\n",
    "print('====== ENDPOINTS ======')\n",
    "print(end_points.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "def logit_with_value(tensor, coordinates, value):\n",
    "    z = tf.zeros_like(tensor[0])\n",
    "    indices = [coordinates]\n",
    "    values = [value]\n",
    "    shape = tf.shape(tensor, out_type=tf.int64)\n",
    "    delta = tf.SparseTensor(indices, values, shape)\n",
    "    return z + tf.sparse_tensor_to_dense(delta)\n",
    "\n",
    "\n",
    "def _prediction_info(predict_values, target_class_index):\n",
    "    predicted_label = np.argmax(predict_values)\n",
    "    class_str = \"{} ({} prob: {:6f})\".format(\n",
    "        predicted_label, labels_mapping[predicted_label], predict_values[0][predicted_label])\n",
    "    target_str = \"For target class {} : {:6f}\".format(\n",
    "        target_class_index, predict_values[0][target_class_index])\n",
    "    return \"{}. {}\".format(class_str, target_str)\n",
    "\n",
    "def plot_example(class_index, iterations=50, decay = 0.0, norm_pct = 0.0, contrib_pct = 0.0, abs_perc = 0.0,\n",
    "                 gausian_kernel_size=0.5, gausian_every=4, learning_rate = 2.0):\n",
    "    im = np.random.normal(size=(IMAGE_SIZE, IMAGE_SIZE, 3), loc=0, scale=1)\n",
    "    im = np.clip(im, -1, 1).astype(np.float32)\n",
    "    im = im.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "    grad_values = logit_with_value(logits, [0, class_index], 1.0)\n",
    "    grad = tf.gradients(logits, input_tensor, grad_ys=grad_values)\n",
    "\n",
    "    res = input_tensor + tf.multiply(grad, tf.constant(learning_rate))\n",
    "    \n",
    "    modified_input = im\n",
    "    for i in range(iterations):\n",
    "        predict_values, modified_image, gradients = sess.run(\n",
    "            [end_points['Predictions'], res, grad], feed_dict={input_tensor: modified_input})\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"{}: {}\".format(i, _prediction_info(predict_values, class_index)))\n",
    "        \n",
    "        regularized = modified_image[0]\n",
    "        if i % 100 == 99:\n",
    "            plt.figure()\n",
    "            plt.suptitle('For {}'.format(i))\n",
    "            plt.imshow(((modified_input[0] + 1.0) * 0.5 * 255.0).astype(np.uint8))\n",
    "        if i + 1 != iterations:\n",
    "            # decay\n",
    "            regularized = regularized * (1.0 - decay)\n",
    "            \n",
    "            # regularize by abs of contribution\n",
    "            activations = np.abs(regularized* gradients[0]).sum(axis=3) # sum over color channels\n",
    "            activations = activations[0]\n",
    "            cutoff = np.percentile(activations, q=contrib_pct)\n",
    "            temp = activations < cutoff\n",
    "            selected = np.zeros((1, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.bool)\n",
    "            selected[0, :, :, 0] = temp\n",
    "            selected[0, :, :, 1] = temp\n",
    "            selected[0, :, :, 2] = temp\n",
    "            regularized[selected] = 0\n",
    "            \n",
    "            # regularize by norm\n",
    "            activations = np.linalg.norm(regularized, axis=3) # norm over color channels\n",
    "            activations = activations[0]\n",
    "            cutoff = np.percentile(activations, q=norm_pct)\n",
    "            temp = activations < cutoff\n",
    "            selected = np.zeros((1, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.bool)\n",
    "            selected[0, :, :, 0] = temp\n",
    "            selected[0, :, :, 1] = temp\n",
    "            selected[0, :, :, 2] = temp\n",
    "            regularized[selected] = 0    \n",
    "\n",
    "            # regularize by abs\n",
    "            activations = np.abs(regularized)\n",
    "            cutoff = np.percentile(activations, q=abs_perc)\n",
    "            regularized[np.abs(regularized) <= cutoff] = 0\n",
    "            \n",
    "            # gausian blur\n",
    "            if gausian_every != 0 and i % gausian_every == gausian_every - 1:\n",
    "                for channel in range(3):\n",
    "                    regularized[:, :, :, channel] = gaussian_filter(regularized[:, :, :, channel], sigma=0.5)\n",
    "        \n",
    "        regularized = np.clip(regularized, -1, 1)\n",
    "                \n",
    "        modified_input = regularized.astype(np.float32)\n",
    "\n",
    "    modified_input = modified_input.astype(np.uint8)\n",
    "    predict_values = sess.run(end_points['Predictions'], feed_dict={input_tensor: modified_input})\n",
    "\n",
    "    print(_prediction_info(predict_values, class_index))\n",
    "\n",
    "    return modified_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TARGET_CLASS = 75 # garden spider\n",
    "TARGET_CLASS = 131 # falmingo\n",
    "ITERATIONS = 2000\n",
    "ATTEMPTS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(ATTEMPTS):\n",
    "    res1 = plot_example(class_index=TARGET_CLASS, iterations=ITERATIONS, decay=0, gausian_kernel_size=0.5, \n",
    "                        gausian_every=4, norm_pct=50.0, contrib_pct=0.0, abs_perc=0.0, learning_rate = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(ATTEMPTS):\n",
    "    res2 = plot_example(class_index=TARGET_CLASS, iterations=ITERATIONS, decay=0.03, gausian_kernel_size=1.0, \n",
    "                        gausian_every=0, norm_pct=15.0, contrib_pct=0.0, abs_perc=0.0, learning_rate = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(ATTEMPTS):\n",
    "    res3 = plot_example(class_index=TARGET_CLASS, iterations=ITERATIONS, decay=0.0001, gausian_kernel_size=0.7, \n",
    "                        gausian_every=4, norm_pct=25.0, contrib_pct=25.0, abs_perc=0.0, learning_rate = 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(ATTEMPTS):\n",
    "    res4 = plot_example(class_index=TARGET_CLASS, iterations=ITERATIONS, decay=0, gausian_kernel_size=0.5, \n",
    "                        gausian_every=4, norm_pct=0.0, contrib_pct=50, abs_perc=0.0, learning_rate = 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
