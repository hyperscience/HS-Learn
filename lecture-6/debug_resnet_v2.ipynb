{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 299\n",
    "\n",
    "TENSORFLOW_MODELS_ROOT = '.'\n",
    "INCEPTION_CHECKPOINT_DIR = '.'\n",
    "CHECKPOINT_FILE = os.path.join(\n",
    "    INCEPTION_CHECKPOINT_DIR, 'inception_resnet_v2_2016_08_30.ckpt')\n",
    "\n",
    "MALAMUTE_PATH = './images/malamute.png'\n",
    "HUSKY_PATH = './images/Siberian-husky.jpg'\n",
    "\n",
    "MALAMUTE_IMAGE = Image.open(MALAMUTE_PATH)\n",
    "HUSKY_IMAGE = Image.open(HUSKY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToJpeg(im):\n",
    "    with BytesIO() as f:\n",
    "        im.save(f, format='JPEG')\n",
    "        return f.getvalue()\n",
    "    \n",
    "\n",
    "def create_readable_names_for_imagenet_labels():\n",
    "    \"\"\"Create a dict mapping label id to human readable string.\n",
    "    Returns:\n",
    "      labels_to_names: dictionary where keys are integers from to 1000\n",
    "      and values are human-readable names.\n",
    "    We retrieve a synset file, which contains a list of valid synset labels used\n",
    "    by ILSVRC competition. There is one synset one per line, eg.\n",
    "          #   n01440764\n",
    "          #   n01443537\n",
    "    We also retrieve a synset_to_human_file, which contains a mapping from synsets\n",
    "    to human-readable names for every synset in Imagenet. These are stored in a\n",
    "    tsv format, as follows:\n",
    "          #   n02119247    black fox\n",
    "          #   n02119359    silver fox\n",
    "    We assign each synset (in alphabetical order) an integer, starting from 1\n",
    "    (since 0 is reserved for the background class).\n",
    "    \"\"\"\n",
    "\n",
    "    # pylint: disable=g-line-too-long\n",
    "    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/slim/datasets'\n",
    "    synset_url = '{}/imagenet_lsvrc_2015_synsets.txt'.format(base_url)\n",
    "    synset_to_human_url = '{}/imagenet_metadata.txt'.format(base_url)\n",
    "\n",
    "    synset_list = [s.strip() for s in requests.get(synset_url).content.decode().split('\\n') if len(s.strip())]\n",
    "    num_synsets_in_ilsvrc = len(synset_list)\n",
    "    print(synset_list[-1])\n",
    "    assert num_synsets_in_ilsvrc == 1000\n",
    "\n",
    "    synset_to_human_list = requests.get(synset_to_human_url).content.decode().split('\\n')[:-1]\n",
    "    num_synsets_in_all_imagenet = len(synset_to_human_list)\n",
    "    assert num_synsets_in_all_imagenet == 21842\n",
    "\n",
    "    synset_to_human = {}\n",
    "    for s in synset_to_human_list:\n",
    "        parts = s.strip().split('\\t')\n",
    "        assert len(parts) == 2\n",
    "        synset = parts[0]\n",
    "        human = parts[1]\n",
    "        synset_to_human[synset] = human\n",
    "\n",
    "    label_index = 1\n",
    "    labels_to_names = {0: 'background'}\n",
    "    for synset in synset_list:\n",
    "        name = synset_to_human[synset]\n",
    "        labels_to_names[label_index] = name\n",
    "        label_index += 1\n",
    "\n",
    "    return labels_to_names\n",
    "\n",
    "labels_mapping = create_readable_names_for_imagenet_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "from skimage.io import imread, imsave, imshow\n",
    "\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase plot sizes\n",
    "plt.rcParams['figure.figsize'] = (15, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(\n",
    "    TENSORFLOW_MODELS_ROOT, 'models/research/slim/nets'))\n",
    "from inception_resnet_v2 import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tf.placeholder(tf.float32, shape=(None,IMAGE_SIZE,IMAGE_SIZE,3), name='input_image')\n",
    "scaled_input_tensor = tf.scalar_mul((1.0/255), input_tensor)\n",
    "scaled_input_tensor = tf.subtract(scaled_input_tensor, 0.5)\n",
    "scaled_input_tensor = tf.multiply(scaled_input_tensor, 2.0)\n",
    "\n",
    "print(scaled_input_tensor)\n",
    "#Load the model\n",
    "arg_scope = inception_resnet_v2_arg_scope()\n",
    "with slim.arg_scope(arg_scope):\n",
    "    logits, end_points = inception_resnet_v2(scaled_input_tensor, is_training=False, reuse=None)\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, CHECKPOINT_FILE)\n",
    "\n",
    "print('====== ENDPOINTS ======')\n",
    "print(end_points.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image, target_tensors):\n",
    "    im = image.convert('RGB').resize((IMAGE_SIZE,IMAGE_SIZE))\n",
    "    np_im = np.array(im)\n",
    "    np_im = np_im.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    return sess.run(target_tensors, feed_dict={input_tensor: np_im}) \n",
    "\n",
    "sample_images = [MALAMUTE_IMAGE, HUSKY_IMAGE]\n",
    "for image in sample_images:\n",
    "    predict_values, logit_values = predict_image(image, [end_points['Predictions'], logits])\n",
    "    print (np.max(predict_values), np.max(logit_values))\n",
    "    predicted_label = np.argmax(predict_values)\n",
    "    print (\"{} : {}\".format(predicted_label, labels_mapping[predicted_label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageDraw \n",
    "\n",
    "\n",
    "def add_black_patch(image, coordinates):\n",
    "    res_image = image.copy()\n",
    "    draw = ImageDraw.Draw(res_image)\n",
    "    black = '#000000'\n",
    "    draw.rectangle(coordinates, fill=black, outline=black)\n",
    "    return res_image\n",
    "\n",
    "\n",
    "def overlay(image, heat_map):\n",
    "    t = np.pad(heat_map, (10, 10), mode='constant')\n",
    "    t = t[10:, 10:]\n",
    "    res = np.zeros(shape=(IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    t2 = (t > 0) * t\n",
    "    t1 = (t < 0) * -t\n",
    "    \n",
    "    minv, maxv = min(t1.min(), t2.min()), max(t1.max(), t2.max())\n",
    "    scale_factor = 1.0\n",
    "    if maxv != minv:\n",
    "        scale_factor = maxv - minv\n",
    "    res[:, :, 0] = (t2 - minv) / scale_factor\n",
    "    res[:, :, 2] = (t1 - minv) / scale_factor\n",
    "    res[:, :, 3] = res[:, :, 0] + res[:, :, 2]\n",
    "    plt.imshow(image.resize((IMAGE_SIZE, IMAGE_SIZE)))\n",
    "    plt.imshow(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot specific filter position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_heat_map(image, layer, filter_index, patch_size=10):\n",
    "    resized_im = image.convert('RGB').resize((IMAGE_SIZE,IMAGE_SIZE))\n",
    "    original_activations = predict_image(resized_im, [end_points[layer]]) \n",
    "    \n",
    "    h, w = resized_im.size\n",
    "    layer_shape = tuple(map(int,  end_points[layer].get_shape()[1:-1]))\n",
    "    activation_map = np.zeros((h - patch_size, w-patch_size) + layer_shape)\n",
    "    print('Desired shape' , activation_map.shape)\n",
    "       \n",
    "    step = 3\n",
    "    for x in range(0, h - patch_size, step):\n",
    "        print('Processing', x // step + 1, 'of', (h - patch_size) // step + 1)\n",
    "        for y in range(0, w - patch_size, step):\n",
    "            temp_im = add_black_patch(resized_im, (x, y, x + patch_size, y + patch_size))\n",
    "            activations = predict_image(temp_im, [end_points[layer]])\n",
    "            activation_map[y:y+step, x:x+step] = (original_activations[0] - activations[0])[0][:, :, filter_index]\n",
    "    return activation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LAYER_NAME= 'Mixed_6a'\n",
    "FILTER_INDEX = 2\n",
    "filter_positions = get_heat_map(MALAMUTE_IMAGE, LAYER_NAME, FILTER_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_neuron2(image, filter_activations, x, y):\n",
    "    selected = filter_activations[:,:, x, y]\n",
    "    if selected.max() - selected.min() == 0:\n",
    "        return\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.suptitle('For ({}, {})'.format(x, y))\n",
    "    overlay(image, selected)   \n",
    "    \n",
    "for x in range(0, 8):\n",
    "    for y in range(0, 8):\n",
    "        plot_neuron2(MALAMUTE_IMAGE, filter_positions, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot whole filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_activation(activations):\n",
    "    mean = np.mean(activations[0][0], axis=(0, 1))\n",
    "    return mean\n",
    "\n",
    "def get_filter_heat_map(image, layer, patch_size=10):\n",
    "    resized_im = image.convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    original_activations = predict_image(resized_im, [end_points[layer]])\n",
    "    number_of_filters = original_activations[0].shape[-1]\n",
    "\n",
    "    original = get_mean_activation(original_activations)\n",
    "    h, w = resized_im.size\n",
    "    activation_map = np.zeros((h - patch_size, w - patch_size, number_of_filters))\n",
    "    print('Desired shape', activation_map.shape)\n",
    "    \n",
    "    step = 3\n",
    "    for x in range(0, h - patch_size, step):\n",
    "        print('Processing', x // step + 1, 'of', (h - patch_size) // step + 1)\n",
    "        for y in range(0, w - patch_size, step):\n",
    "            temp_im = add_black_patch(resized_im, (x, y, x + patch_size, y + patch_size))\n",
    "            activations = predict_image(temp_im, [end_points[layer]])\n",
    "            value = (original - get_mean_activation(activations))\n",
    "            activation_map[y:y+step, x:x+step] = value\n",
    "    return activation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LAYER_NAME= 'Mixed_6a'\n",
    "whole_filters = get_filter_heat_map(MALAMUTE_IMAGE, LAYER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(130):\n",
    "    temp = whole_filters[:, :, i]\n",
    "    if temp.max() - temp.min() == 0:\n",
    "        continue\n",
    "    plt.figure()\n",
    "    plt.suptitle('For {}'.format(i))\n",
    "    overlay(MALAMUTE_IMAGE, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlay_activations(image, layer, filter_index):\n",
    "    resized_im = image.convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    original_activations = predict_image(resized_im, [end_points[layer]])[0][0, :, :, filter_index]\n",
    "    scaled_activations = imresize(\n",
    "        original_activations, size=(IMAGE_SIZE, IMAGE_SIZE), interp='nearest', mode='L')\n",
    "    scaled_activations = scaled_activations / 255\n",
    "    overlay = np.zeros(shape=(IMAGE_SIZE, IMAGE_SIZE, 4))\n",
    "    overlay[:, :, 0] = scaled_activations\n",
    "    overlay[:, :, 1] = scaled_activations * 0.8\n",
    "    overlay[:, :, 3] = scaled_activations\n",
    "    plt.imshow(resized_im)\n",
    "    plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_activations(MALAMUTE_IMAGE, 'Mixed_6a', 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit_with_value(tensor, coordinates, value):\n",
    "    z = tf.zeros_like(tensor[0])\n",
    "    indices = [coordinates]\n",
    "    values = [value]\n",
    "    shape = tf.shape(tensor, out_type=tf.int64)\n",
    "    delta = tf.SparseTensor(indices, values, shape)\n",
    "    return z + tf.sparse_tensor_to_dense(delta)\n",
    "\n",
    "def show_image_safe(im):\n",
    "    temp = im.copy()\n",
    "    temp[temp > 1] = 1\n",
    "    temp[temp < - 1] = -1\n",
    "    imshow(temp)\n",
    "\n",
    "def _prediction_info(predict_values, target_class_index):\n",
    "    predicted_label = np.argmax(predict_values)\n",
    "    class_str = \"{} ({} prob: {:6f})\".format(\n",
    "        predicted_label, labels_mapping[predicted_label], predict_values[0][predicted_label])\n",
    "    target_str = \"For target class {} : {:6f}\".format(\n",
    "        target_class_index, predict_values[0][target_class_index])\n",
    "    return \"{}. {}\".format(class_str, target_str)\n",
    "\n",
    "def get_adversarial_example(image, class_index, iterations=50):\n",
    "    im = image.convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    im = np.array(im)\n",
    "    im = im.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "    grad_values = logit_with_value(logits, [0, class_index], 1.0)\n",
    "    grad = tf.gradients(logits, input_tensor, grad_ys=grad_values)\n",
    "\n",
    "    res = input_tensor + grad\n",
    "\n",
    "    modified_input = im\n",
    "    for i in range(iterations):\n",
    "        predict_values, modified_image = sess.run(\n",
    "            [end_points['Predictions'], res], feed_dict={input_tensor: modified_input})\n",
    "\n",
    "        print(\"{}: {}\".format(i, _prediction_info(predict_values, class_index)))\n",
    "\n",
    "        modified_input = modified_image[0].astype(np.uint8)\n",
    "\n",
    "\n",
    "    predict_values = sess.run(end_points['Predictions'], feed_dict={input_tensor: modified_input})\n",
    "\n",
    "    print(_prediction_info(predict_values, class_index))\n",
    "\n",
    "    return modified_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_example = get_adversarial_example(\n",
    "    MALAMUTE_IMAGE, class_index=131, iterations=20)\n",
    "imshow(adversarial_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deep_dream(image, layer_name, iterations =50):    \n",
    "    im = image.convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    im = np.array(im)\n",
    "    im = im.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    \n",
    "    grad = tf.gradients(end_points[layer_name], input_tensor, grad_ys=end_points[layer_name])\n",
    "    \n",
    "    res = input_tensor + grad\n",
    "    \n",
    "    modified_input = im\n",
    "    for i in range(iterations):\n",
    "        modified_image = sess.run(res, feed_dict={input_tensor: modified_input})\n",
    "        modified_input = modified_image[0].astype(np.uint8)\n",
    "   \n",
    "    \n",
    "    return modified_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(deep_dream(MALAMUTE_IMAGE, 'Mixed_6a', iterations=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(deep_dream(MALAMUTE_IMAGE, 'Mixed_7a', iterations=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(deep_dream(MALAMUTE_IMAGE, 'Conv2d_7b_1x1', iterations=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
